{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2024-03-12T15:45:24.780689Z","iopub.status.busy":"2024-03-12T15:45:24.780301Z","iopub.status.idle":"2024-03-12T15:45:30.573237Z","shell.execute_reply":"2024-03-12T15:45:30.572159Z","shell.execute_reply.started":"2024-03-12T15:45:24.780656Z"},"trusted":true},"outputs":[],"source":["from torchtext.data.utils import get_tokenizer\n","from torchtext.vocab import build_vocab_from_iterator\n","from typing import Iterable, List\n","from torch.nn.utils.rnn import pad_sequence\n","from torch.utils.data import DataLoader, Dataset\n","from torch.nn import Transformer\n","from torch import Tensor\n","from tqdm.auto import tqdm\n","import torch.nn as nn\n","import torch\n","import torch.nn.functional as F\n","import numpy as np\n","import math\n","import os\n","#import wandb"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-09T22:53:48.497323Z","iopub.status.busy":"2024-03-09T22:53:48.497001Z","iopub.status.idle":"2024-03-09T22:53:51.163336Z","shell.execute_reply":"2024-03-09T22:53:51.162400Z","shell.execute_reply.started":"2024-03-09T22:53:48.497298Z"},"trusted":true},"outputs":[],"source":["#wandb.login(key='')"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-09T22:53:51.165407Z","iopub.status.busy":"2024-03-09T22:53:51.164530Z","iopub.status.idle":"2024-03-09T22:53:51.173282Z","shell.execute_reply":"2024-03-09T22:53:51.172387Z","shell.execute_reply.started":"2024-03-09T22:53:51.165379Z"},"trusted":true},"outputs":[],"source":["seed = 42\n","np.random.seed(seed)\n","torch.manual_seed(seed)\n","torch.cuda.manual_seed(seed)\n","torch.backends.cudnn.deterministic = True\n","torch.backends.cudnn.benchmark = True"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-09T22:53:51.176683Z","iopub.status.busy":"2024-03-09T22:53:51.176346Z","iopub.status.idle":"2024-03-09T22:53:51.181587Z","shell.execute_reply":"2024-03-09T22:53:51.180666Z","shell.execute_reply.started":"2024-03-09T22:53:51.176645Z"},"trusted":true},"outputs":[],"source":["SRC_LANGUAGE = 'de'\n","TGT_LANGUAGE = 'en'"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-09T22:53:51.183087Z","iopub.status.busy":"2024-03-09T22:53:51.182829Z","iopub.status.idle":"2024-03-09T22:53:51.191732Z","shell.execute_reply":"2024-03-09T22:53:51.190884Z","shell.execute_reply.started":"2024-03-09T22:53:51.183064Z"},"trusted":true},"outputs":[],"source":["token_transform = {}\n","vocab_transform = {}\n","token_transform[SRC_LANGUAGE] = get_tokenizer(None, language='de_core_news_sm')\n","token_transform[TGT_LANGUAGE] = get_tokenizer(None, language='en_core_news_sm')\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-09T22:53:51.193041Z","iopub.status.busy":"2024-03-09T22:53:51.192752Z","iopub.status.idle":"2024-03-09T22:53:52.497516Z","shell.execute_reply":"2024-03-09T22:53:52.496757Z","shell.execute_reply.started":"2024-03-09T22:53:51.193018Z"},"trusted":true},"outputs":[],"source":["import numpy as np\n","\n","\n","with open('/kaggle/input/bhw2-dataset-torbakhov/data-2/train.de-en.de', 'r') as file:\n","    des = [t.rstrip() for t in file.readlines()]\n","\n","with open('/kaggle/input/bhw2-dataset-torbakhov/data-2/train.de-en.en', 'r') as file:\n","    ens = [t.rstrip() for t in file.readlines()]\n","\n","train = np.array([des, ens]).T\n","\n","with open('/kaggle/input/bhw2-dataset-torbakhov/data-2/val.de-en.de', 'r') as file:\n","    des_val = [t.rstrip() for t in file.readlines()]\n","\n","with open('/kaggle/input/bhw2-dataset-torbakhov/data-2/val.de-en.en', 'r') as file:\n","    ens_val = [t.rstrip() for t in file.readlines()]\n","\n","valid = np.array([des_val, ens_val]).T"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-09T22:53:52.498908Z","iopub.status.busy":"2024-03-09T22:53:52.498635Z","iopub.status.idle":"2024-03-09T22:53:52.504548Z","shell.execute_reply":"2024-03-09T22:53:52.503625Z","shell.execute_reply.started":"2024-03-09T22:53:52.498886Z"},"trusted":true},"outputs":[],"source":["# Custom Dataset class.\n","class TranslationDataset(Dataset):\n","    def __init__(self, data):\n","        self.data = data\n","        \n","    def __len__(self):\n","        return len(self.data)\n","    \n","    def __getitem__(self, idx):\n","        return(\n","            self.data[idx, 0],\n","            self.data[idx, 1]\n","        )"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-09T22:53:52.506681Z","iopub.status.busy":"2024-03-09T22:53:52.506347Z","iopub.status.idle":"2024-03-09T22:53:52.514244Z","shell.execute_reply":"2024-03-09T22:53:52.513422Z","shell.execute_reply.started":"2024-03-09T22:53:52.506658Z"},"trusted":true},"outputs":[],"source":["train_dataset = TranslationDataset(train)\n","valid_dataset = TranslationDataset(valid)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-09T22:53:53.884708Z","iopub.status.busy":"2024-03-09T22:53:53.884295Z","iopub.status.idle":"2024-03-09T22:53:53.889351Z","shell.execute_reply":"2024-03-09T22:53:53.888305Z","shell.execute_reply.started":"2024-03-09T22:53:53.884675Z"},"trusted":true},"outputs":[],"source":["SRC_LANGUAGE = 'de'\n","TGT_LANGUAGE = 'en'"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-09T22:53:55.091429Z","iopub.status.busy":"2024-03-09T22:53:55.091063Z","iopub.status.idle":"2024-03-09T22:54:00.202106Z","shell.execute_reply":"2024-03-09T22:54:00.200701Z","shell.execute_reply.started":"2024-03-09T22:53:55.091402Z"},"trusted":true},"outputs":[],"source":["# https://pytorch.org/tutorials/beginner/translation_transformer.html\n","\n","def yield_tokens(data_iter: Iterable, language: str) -> List[str]:\n","    language_index = {SRC_LANGUAGE: 0, TGT_LANGUAGE: 1}\n","    for data_sample in data_iter:\n","        yield token_transform[language](data_sample[language_index[language]])\n","\n","UNK_IDX, PAD_IDX, BOS_IDX, EOS_IDX = 0, 1, 2, 3\n","\n","special_symbols = ['<unk>', '<pad>', '<bos>', '<eos>']\n","for ln in [SRC_LANGUAGE, TGT_LANGUAGE]:\n","    vocab_transform[ln] = build_vocab_from_iterator(\n","        yield_tokens(train_dataset, ln),\n","        min_freq=1,\n","        specials=special_symbols,\n","        special_first=True,\n","    )\n","\n","for ln in [SRC_LANGUAGE, TGT_LANGUAGE]:\n","    vocab_transform[ln].set_default_index(UNK_IDX)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-09T22:54:00.216232Z","iopub.status.busy":"2024-03-09T22:54:00.215808Z","iopub.status.idle":"2024-03-09T22:54:00.245413Z","shell.execute_reply":"2024-03-09T22:54:00.244079Z","shell.execute_reply.started":"2024-03-09T22:54:00.216195Z"},"trusted":true},"outputs":[],"source":["# https://pytorch.org/tutorials/beginner/transformer_tutorial.html\n","\n","class PositionalEncoding(nn.Module):\n","    def __init__(self, d_model, dropout, max_len=5000):\n","        \"\"\"\n","        :param max_len: Input length sequence.\n","        :param d_model: Embedding dimension.\n","        :param dropout: Dropout value (default=0.1)\n","        \"\"\"\n","        super(PositionalEncoding, self).__init__()\n","        self.dropout = nn.Dropout(p=dropout)\n","        \n","        \n","        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n","        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n","        pe = torch.zeros(max_len, d_model)\n","        pe[:, 0::2] = torch.sin(position * div_term)\n","        pe[:, 1::2] = torch.cos(position * div_term)\n","        pe = pe.unsqueeze(0)\n","        self.register_buffer('pe', pe)\n","    def forward(self, x):\n","        \"\"\"\n","        Inputs of forward function\n","        :param x: the sequence fed to the positional encoder model (required).\n","        Shape:\n","            x: [sequence length, batch size, embed dim]\n","            output: [sequence length, batch size, embed dim]\n","        \"\"\"\n","        x = x + self.pe[:, :x.size(1)]\n","        return self.dropout(x)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-09T22:54:00.248520Z","iopub.status.busy":"2024-03-09T22:54:00.248199Z","iopub.status.idle":"2024-03-09T22:54:00.273154Z","shell.execute_reply":"2024-03-09T22:54:00.272281Z","shell.execute_reply.started":"2024-03-09T22:54:00.248494Z"},"trusted":true},"outputs":[],"source":["# https://pytorch.org/tutorials/beginner/translation_transformer.html\n","\n","def sequential_transforms(*transforms):\n","    def func(txt_input):\n","        for transform in transforms:\n","            txt_input = transform(txt_input)\n","        return txt_input\n","    return func\n","\n","def tensor_transform(token_ids: List[int]):\n","    return torch.cat((torch.tensor([BOS_IDX]),\n","                      torch.tensor(token_ids),\n","                      torch.tensor([EOS_IDX])))\n","\n","text_transform = {}\n","for ln in [SRC_LANGUAGE, TGT_LANGUAGE]:\n","    text_transform[ln] = sequential_transforms(token_transform[ln],\n","                                               vocab_transform[ln],\n","                                               tensor_transform)\n","\n","def collate_fn(batch):\n","    src_batch, tgt_batch = [], []\n","    for src_sample, tgt_sample in batch:\n","        src_batch.append(text_transform[SRC_LANGUAGE](src_sample.rstrip(\"\\n\")))\n","        tgt_batch.append(text_transform[TGT_LANGUAGE](tgt_sample.rstrip(\"\\n\")))\n","    src_batch = pad_sequence(src_batch, padding_value=PAD_IDX, batch_first=True)\n","    tgt_batch = pad_sequence(tgt_batch, padding_value=PAD_IDX, batch_first=True)\n","    return src_batch, tgt_batch\n","\n","def generate_square_subsequent_mask(sz):\n","    mask = (torch.triu(torch.ones((sz, sz), device=DEVICE)) == 1).transpose(0, 1)\n","    mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n","    return mask\n","def create_mask(src, tgt):\n","    src_seq_len = src.shape[1]\n","    tgt_seq_len = tgt.shape[1]\n","    tgt_mask = generate_square_subsequent_mask(tgt_seq_len)\n","    src_mask = torch.zeros((src_seq_len, src_seq_len),device=DEVICE).type(torch.bool)\n","    src_padding_mask = (src == PAD_IDX)\n","    tgt_padding_mask = (tgt == PAD_IDX)\n","    return src_mask, tgt_mask, src_padding_mask, tgt_padding_mask\n","\n","class TokenEmbedding(nn.Module):\n","    def __init__(self, vocab_size: int, emb_size):\n","        super(TokenEmbedding, self).__init__()\n","        self.embedding = nn.Embedding(vocab_size, emb_size)\n","        self.emb_size = emb_size\n","    def forward(self, tokens: Tensor):\n","        return self.embedding(tokens.long()) * math.sqrt(self.emb_size)\n","\n","class Seq2SeqTransformer(nn.Module):\n","    def __init__(\n","        self,\n","        num_encoder_layers: int,\n","        num_decoder_layers: int,\n","        emb_size: int,\n","        nhead: int,\n","        src_vocab_size: int,\n","        tgt_vocab_size: int,\n","        dim_feedforward: int = 512,\n","        dropout: float = 0.1\n","    ):\n","        super(Seq2SeqTransformer, self).__init__()\n","        self.transformer = Transformer(d_model=emb_size,\n","                                       nhead=nhead,\n","                                       num_encoder_layers=num_encoder_layers,\n","                                       num_decoder_layers=num_decoder_layers,\n","                                       dim_feedforward=dim_feedforward,\n","                                       dropout=dropout,\n","                                       batch_first=True)\n","        self.generator = nn.Linear(emb_size, tgt_vocab_size)\n","        self.src_tok_emb = TokenEmbedding(src_vocab_size, emb_size)\n","        self.tgt_tok_emb = TokenEmbedding(tgt_vocab_size, emb_size)\n","        self.positional_encoding = PositionalEncoding(\n","            emb_size, dropout=dropout)\n","    def forward(self,\n","                src: Tensor,\n","                trg: Tensor,\n","                src_mask: Tensor,\n","                tgt_mask: Tensor,\n","                src_padding_mask: Tensor,\n","                tgt_padding_mask: Tensor,\n","                memory_key_padding_mask: Tensor):\n","        src_emb = self.positional_encoding(self.src_tok_emb(src))\n","        tgt_emb = self.positional_encoding(self.tgt_tok_emb(trg))\n","        outs = self.transformer(src_emb, tgt_emb, src_mask, tgt_mask, None,\n","                                src_padding_mask, tgt_padding_mask, memory_key_padding_mask)\n","        return self.generator(outs)\n","    def encode(self, src: Tensor, src_mask: Tensor):\n","        return self.transformer.encoder(self.positional_encoding(\n","                            self.src_tok_emb(src)), src_mask)\n","    def decode(self, tgt: Tensor, memory: Tensor, tgt_mask: Tensor):\n","        return self.transformer.decoder(self.positional_encoding(\n","                          self.tgt_tok_emb(tgt)), memory,\n","                          tgt_mask)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-09T22:54:00.274978Z","iopub.status.busy":"2024-03-09T22:54:00.274680Z","iopub.status.idle":"2024-03-09T22:54:00.286235Z","shell.execute_reply":"2024-03-09T22:54:00.285340Z","shell.execute_reply.started":"2024-03-09T22:54:00.274955Z"},"trusted":true},"outputs":[],"source":["# def log_train(train_loss, val_loss):   \n","#     wandb.log({\"train_loss\": train_loss, \"val_loss\": val_loss})"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-09T22:54:00.287826Z","iopub.status.busy":"2024-03-09T22:54:00.287425Z","iopub.status.idle":"2024-03-09T22:54:00.296988Z","shell.execute_reply":"2024-03-09T22:54:00.296121Z","shell.execute_reply.started":"2024-03-09T22:54:00.287790Z"},"trusted":true},"outputs":[],"source":["SRC_VOCAB_SIZE = len(vocab_transform[SRC_LANGUAGE])\n","TGT_VOCAB_SIZE = len(vocab_transform[TGT_LANGUAGE])\n","EMB_SIZE = 1024\n","NHEAD = 8\n","FFN_HID_DIM = 512\n","BATCH_SIZE = 64\n","NUM_ENCODER_LAYERS = 3\n","NUM_DECODER_LAYERS = 3\n","DEVICE = 'cuda'\n","NUM_EPOCHS = 15"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-09T22:54:01.571169Z","iopub.status.busy":"2024-03-09T22:54:01.570820Z","iopub.status.idle":"2024-03-09T22:54:02.333039Z","shell.execute_reply":"2024-03-09T22:54:02.331345Z","shell.execute_reply.started":"2024-03-09T22:54:01.571136Z"},"trusted":true},"outputs":[],"source":["model = Seq2SeqTransformer(\n","    NUM_ENCODER_LAYERS, \n","    NUM_DECODER_LAYERS, \n","    EMB_SIZE,\n","    NHEAD, \n","    SRC_VOCAB_SIZE, \n","    TGT_VOCAB_SIZE, \n","    FFN_HID_DIM\n",").to(DEVICE)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-08T14:39:35.635429Z","iopub.status.busy":"2024-03-08T14:39:35.634587Z","iopub.status.idle":"2024-03-08T14:39:35.644075Z","shell.execute_reply":"2024-03-08T14:39:35.643162Z","shell.execute_reply.started":"2024-03-08T14:39:35.635397Z"},"trusted":true},"outputs":[],"source":["loss_fn = torch.nn.CrossEntropyLoss(ignore_index=PAD_IDX)\n","optimizer = torch.optim.Adam(model.parameters(), lr=0.0001, betas=(0.9, 0.98), eps=1e-9)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-08T14:39:37.158910Z","iopub.status.busy":"2024-03-08T14:39:37.158560Z","iopub.status.idle":"2024-03-08T14:39:37.174154Z","shell.execute_reply":"2024-03-08T14:39:37.173069Z","shell.execute_reply.started":"2024-03-08T14:39:37.158883Z"},"trusted":true},"outputs":[],"source":["train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, collate_fn=collate_fn)\n","def train_epoch(model, optimizer):\n","    print('Training')\n","    model.train()\n","    losses = 0\n","    for src, tgt in tqdm(train_dataloader, total=len(list(train_dataloader))):            \n","        src = src.to(DEVICE)\n","        tgt = tgt.to(DEVICE)\n","                \n","        tgt_input = tgt[:, :-1]\n","        \n","        src_mask, tgt_mask, src_padding_mask, tgt_padding_mask = create_mask(src, tgt_input)\n","        logits = model(\n","            src, \n","            tgt_input, \n","            src_mask, \n","            tgt_mask,\n","            src_padding_mask, \n","            tgt_padding_mask, \n","            src_padding_mask\n","        )\n","        optimizer.zero_grad()\n","        tgt_out = tgt[:, 1:]\n","        loss = loss_fn(logits.view(-1, TGT_VOCAB_SIZE), tgt_out.contiguous().view(-1))\n","        loss.backward()\n","        optimizer.step()\n","        losses += loss.item()\n","        torch.cuda.empty_cache()\n","        \n","    return losses / len(list(train_dataloader))\n","\n","val_dataloader = DataLoader(valid_dataset, batch_size=BATCH_SIZE, collate_fn=collate_fn)\n","@torch.no_grad()\n","def evaluate(model):\n","    print('Validating')\n","    model.eval()\n","    losses = 0\n","    for src, tgt in tqdm(val_dataloader, total=len(list(val_dataloader))):\n","        # print(\" \".join(vocab_transform[SRC_LANGUAGE].lookup_tokens(list(src[0].cpu().numpy()))).replace(\"<bos>\", \"\").replace(\"<eos>\", \"\"))\n","        # print(\" \".join(vocab_transform[TGT_LANGUAGE].lookup_tokens(list(tgt[0].cpu().numpy()))).replace(\"<bos>\", \"\").replace(\"<eos>\", \"\"))\n","        src = src.to(DEVICE)\n","        tgt = tgt.to(DEVICE)\n","        \n","        tgt_input = tgt[:, :-1]\n","        \n","        src_mask, tgt_mask, src_padding_mask, tgt_padding_mask = create_mask(src, tgt_input)\n","        \n","        logits = model(\n","            src, \n","            tgt_input, \n","            src_mask, \n","            tgt_mask,\n","            src_padding_mask, \n","            tgt_padding_mask, \n","            src_padding_mask\n","        )\n","        tgt_out = tgt[:, 1:]\n","        loss = loss_fn(logits.view(-1, TGT_VOCAB_SIZE), tgt_out.contiguous().view(-1))\n","        losses += loss.item()\n","        torch.cuda.empty_cache()\n","        \n","    return losses / len(list(val_dataloader))"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-08T14:39:38.258825Z","iopub.status.busy":"2024-03-08T14:39:38.258462Z","iopub.status.idle":"2024-03-08T14:40:14.392701Z","shell.execute_reply":"2024-03-08T14:40:14.391888Z","shell.execute_reply.started":"2024-03-08T14:39:38.258796Z"},"trusted":true},"outputs":[],"source":["# wandb.init(project=\"bhw2\", config={\"dataset\": \"kaggle-dataset\"}, name=\"Seq2Seq\")\n","# wandb.config.epochs = NUM_EPOCHS\n","# wandb.config.optimizer = \"Adam\"\n","# wandb.config.criterion = \"CrossEntropyLoss\"\n","# wandb.config.scheduler = \"None\"\n","# wandb.config.learning_rate = \"0.0001\"\n","# wandb.config.hidden = FFN_HID_DIM\n","# wandb.config.emb_size = EMB_SIZE\n","# wandb.config.nheads = NHEAD\n","# wandb.config.batch_size = BATCH_SIZE"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-08T14:40:19.245134Z","iopub.status.busy":"2024-03-08T14:40:19.244669Z","iopub.status.idle":"2024-03-08T14:57:35.094949Z","shell.execute_reply":"2024-03-08T14:57:35.093854Z","shell.execute_reply.started":"2024-03-08T14:40:19.245095Z"},"trusted":true},"outputs":[],"source":["train_loss_list, valid_loss_list = [], []\n","for epoch in range(1, NUM_EPOCHS+1):\n","    train_loss = train_epoch(model, optimizer)\n","    valid_loss = evaluate(model)\n","    train_loss_list.append(train_loss)\n","    valid_loss_list.append(valid_loss)\n","#     log_train(train_loss, valid_loss)\n","    print((f\"Epoch: {epoch}, Train loss: {train_loss:.3f}, Val loss: {valid_loss:.3f} \\n\"))"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-08T14:57:45.398207Z","iopub.status.busy":"2024-03-08T14:57:45.397135Z","iopub.status.idle":"2024-03-08T14:57:45.402229Z","shell.execute_reply":"2024-03-08T14:57:45.401227Z","shell.execute_reply.started":"2024-03-08T14:57:45.398176Z"},"trusted":true},"outputs":[],"source":["os.makedirs('outputs', exist_ok=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-08T14:57:46.551190Z","iopub.status.busy":"2024-03-08T14:57:46.550803Z","iopub.status.idle":"2024-03-08T14:57:47.567495Z","shell.execute_reply":"2024-03-08T14:57:47.566580Z","shell.execute_reply.started":"2024-03-08T14:57:46.551161Z"},"trusted":true},"outputs":[],"source":["torch.save(model, 'outputs/model.pth')"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-08T14:57:48.400445Z","iopub.status.busy":"2024-03-08T14:57:48.400118Z","iopub.status.idle":"2024-03-08T14:57:48.843475Z","shell.execute_reply":"2024-03-08T14:57:48.842689Z","shell.execute_reply.started":"2024-03-08T14:57:48.400421Z"},"trusted":true},"outputs":[],"source":["model = torch.load('outputs/model.pth')"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-08T14:57:49.593356Z","iopub.status.busy":"2024-03-08T14:57:49.592993Z","iopub.status.idle":"2024-03-08T14:57:49.604606Z","shell.execute_reply":"2024-03-08T14:57:49.603785Z","shell.execute_reply.started":"2024-03-08T14:57:49.593326Z"},"trusted":true},"outputs":[],"source":["def greedy_decode(model, src, src_mask, max_len, start_symbol):\n","    src = src.to(DEVICE)\n","    src_mask = src_mask.to(DEVICE)\n","    memory = model.encode(src, src_mask)\n","    ys = torch.ones(1, 1).fill_(start_symbol).type(torch.long).to(DEVICE)\n","    for i in range(max_len-1):\n","        memory = memory.to(DEVICE)\n","        if i == 0:\n","            ys = ys.transpose(1, 0)\n","        tgt_mask = (generate_square_subsequent_mask(ys.size(1))\n","                    .type(torch.bool)).to(DEVICE)\n","        out = model.decode(ys, memory, tgt_mask)\n","        out = out\n","        prob = model.generator(out[:, -1])\n","        _, next_word = torch.max(prob, dim=1)\n","        next_word = next_word.item()\n","        ys = torch.cat([ys,\n","                        torch.ones(1, 1).type_as(src.data).fill_(next_word)], dim=1)\n","        if next_word == EOS_IDX:\n","            break\n","    return ys\n","\n","def translate(model: torch.nn.Module, src_sentence: str):\n","    model.eval()\n","    src = text_transform[SRC_LANGUAGE](src_sentence).view(1, -1)\n","    num_tokens = src.shape[1]\n","    src_mask = (torch.zeros(num_tokens, num_tokens)).type(torch.bool)\n","    tgt_tokens = greedy_decode(\n","        model,  src, src_mask, max_len=num_tokens + 5, start_symbol=BOS_IDX).flatten()\n","    return \" \".join(vocab_transform[TGT_LANGUAGE].lookup_tokens(list(tgt_tokens.cpu().numpy()))).replace(\"<bos>\", \"\").replace(\"<eos>\", \"\")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-08T14:57:51.663472Z","iopub.status.busy":"2024-03-08T14:57:51.663114Z","iopub.status.idle":"2024-03-08T14:57:52.106139Z","shell.execute_reply":"2024-03-08T14:57:52.105212Z","shell.execute_reply.started":"2024-03-08T14:57:51.663442Z"},"trusted":true},"outputs":[],"source":["infer_sentences = [valid_dataset[0], valid_dataset[1], valid_dataset[2], valid_dataset[3]]\n","for sentence in infer_sentences:\n","    print(f\"SRC: {sentence[0]}\")\n","    print(f\"GT: {sentence[1]}\")\n","    print(f\"PRED: {translate(model, sentence[0])}\\n\")"]},{"cell_type":"code","execution_count":null,"metadata":{"_kg_hide-output":true,"execution":{"iopub.execute_input":"2024-03-08T14:58:13.468436Z","iopub.status.busy":"2024-03-08T14:58:13.468097Z","iopub.status.idle":"2024-03-08T15:03:03.299009Z","shell.execute_reply":"2024-03-08T15:03:03.298096Z","shell.execute_reply.started":"2024-03-08T14:58:13.468412Z"},"trusted":true},"outputs":[],"source":["with open('/kaggle/input/bhw2-dataset-torbakhov/data-2/test1.de-en.de', 'r') as file:\n","    ens = [t.rstrip() for t in file.readlines()]\n","    with open('results.txt', 'w') as f:\n","        for sentence in ens:\n","            res = translate(model, sentence)\n","            res += '\\n'\n","            f.write(res)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"datasetId":4499213,"sourceId":7706314,"sourceType":"datasetVersion"}],"dockerImageVersionId":30648,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":4}
