{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "f1c368f2",
      "metadata": {
        "id": "f1c368f2"
      },
      "source": [
        "# Глубинное обучение 1 / Введение в глубинное обучение, ФКН ВШЭ\n",
        "\n",
        "## Домашнее задание 3: RNN и языковые модели\n",
        "\n",
        "### Общая информация\n",
        "\n",
        "Оценка после штрафа после мягкого дедлайна вычисляется по формуле $M_{\\text{penalty}} = M_{\\text{full}} \\cdot 0.85^{t/1440}$, где $M_{\\text{full}}$ — полная оценка за работу без учета штрафа, а $t$ — время в минутах, прошедшее после мягкого дедлайна (округление до двух цифр после запятой). Таким образом, спустя первые сутки после мягкого дедлайна вы не можете получить оценку выше 12.75, а если сдать через четыре дня после мягкого дедлайна, то ваш максимум — 7.83 балла.\n",
        "\n",
        "### Оценивание и штрафы\n",
        "\n",
        "Максимально допустимая оценка за работу — 15 баллов. Сдавать задание после указанного срока сдачи нельзя.\n",
        "\n",
        "Задание выполняется самостоятельно. «Похожие» решения считаются плагиатом и все задействованные студенты (в том числе те, у кого списали) не могут получить за него больше 0 баллов. Если вы нашли решение какого-то из заданий (или его часть) в открытом источнике, необходимо указать ссылку на этот источник в отдельном блоке в конце вашей работы (скорее всего вы будете не единственным, кто это нашел, поэтому чтобы исключить подозрение в плагиате, необходима ссылка на источник).\n",
        "\n",
        "Неэффективная реализация кода может негативно отразиться на оценке. Также оценка может быть снижена за плохо читаемый код и плохо оформленные графики. Все ответы должны сопровождаться кодом или комментариями о том, как они были получены.\n",
        "\n",
        "### О задании\n",
        "\n",
        "В этом задании вам предстоит обучить рекуррентную нейронную сеть для задачи генерации текстов. В качестве данных возьмем набор из 120 тысяч анекдотов (всех категорий от А до Я включительно). Его вы можете найти в архиве `jokes.txt.zip`, который доступен по [ссылке](https://disk.yandex.com/d/fjt5xICH-ukEEA)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "b35b1cee",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b35b1cee",
        "outputId": "c58c655d-a9df-4666-d9c5-ab972a9cbae3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The autoreload extension is already loaded. To reload it, use:\n",
            "  %reload_ext autoreload\n"
          ]
        }
      ],
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1daae037",
      "metadata": {
        "id": "1daae037"
      },
      "source": [
        "## Задание 1: Dataset (1 балл)\n",
        "\n",
        "В этом задании мы будет пользоваться библиотекой [sentencepiece](https://github.com/google/sentencepiece), которая поддерживает разные форматы токенизации текстов, в том числе BPE, который мы и будем использовать. Реализуйте недостающие фрагменты кода в классе `TextDataset` в файле `dataset.py`. Датасет обучает sentencepiece токенизатор, токенизирует тексты, превращает токены в индексы и паддит до одной и той же длины (параметр `max_length`). Не забудьте, что для генерации текстов нам будут нужны специальные токены начала и конца последовательности, соответственно `BOS` и `EOS`. Существуют еще два специальных токена &mdash; паддинг `PAD` и токен `UNK`, заменяющий out-of-vocabulary токены."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "2dfa4648",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2dfa4648",
        "outputId": "372eae85-6120-4478-9001-047a3879b185"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (0.1.99)\n"
          ]
        }
      ],
      "source": [
        "!pip install sentencepiece"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "a0ed11c5",
      "metadata": {
        "id": "a0ed11c5"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "from dataset import TextDataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "81630e30",
      "metadata": {
        "id": "81630e30"
      },
      "outputs": [],
      "source": [
        "train_set = TextDataset(data_file='jokes.txt', train=True, sp_model_prefix='bpe')\n",
        "valid_set = TextDataset(data_file='jokes.txt', train=False, sp_model_prefix='bpe')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "27555b9a",
      "metadata": {
        "id": "27555b9a"
      },
      "outputs": [],
      "source": [
        "# Код должен проходить тесты\n",
        "assert len(train_set) + len(valid_set) == 120759\n",
        "\n",
        "for _ in range(5):\n",
        "    for dataset in (train_set, valid_set):\n",
        "        indices, length = dataset[np.random.randint(len(dataset))]\n",
        "        assert indices.shape == (dataset.max_length, )\n",
        "        assert indices[0].item() == dataset.bos_id\n",
        "        assert (indices == dataset.eos_id).sum().item() == 1\n",
        "\n",
        "        eos_pos = indices.tolist().index(dataset.eos_id)\n",
        "        assert torch.all(indices[eos_pos + 1:] == dataset.pad_id)\n",
        "        assert (indices != dataset.pad_id).sum() == length"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5db087d5",
      "metadata": {
        "id": "5db087d5"
      },
      "source": [
        "## Задание 2 Language model (3.5 балла)\n",
        "\n",
        "Реализуйте класс `LanguageModel` из файла `model.py`. Мы будем генерировать текст с помощью языковой модели &mdash; это авторегрессионная вероятностная модель, которая предсказывает распределение следующего токена при условии предыдущих:\n",
        "\n",
        "$$\n",
        "p(x_1, x_2, x_3, \\dots, x_T) = p(x_1) \\cdot p(x_2 | x_1) \\cdot p(x_3|x_1, x_2) \\, \\cdot \\, \\dots \\, \\cdot \\, p(x_T|x_1, \\dots, x_{T-1})\n",
        "$$\n",
        "\n",
        "Мы будем реализовывать ее с помощью рекуррентной нейронной сети. Ваш код должен поддерживать возможность работать как с оригинальной [RNN](https://pytorch.org/docs/stable/generated/torch.nn.RNN.html#torch.nn.RNN), так и c [LSTM](https://bitly.com/98K8eH). На каждом временном шаге модель возвращает логиты вероятностей для следующего токена. Модель будет работать в двух режимах (не путать с `.train()` и `.eval()`):\n",
        "\n",
        "- В режиме обучения (метод `forward`) модель принимает настоящие последовательности из датасета и их длины. На каждом временном шаге возвращаются логиты вероятностей следующего токена, что позволяет считать лосс, обучаться на трейне и валидироваться на валидации.\n",
        "\n",
        "- В режиме генерации (инференса, метод `inference`) модель принимает некоторый префикс (возможно пустой), с которого начинать генерацию, и продолжает его. Для этого на каждом шаге генерируются новые логиты, семплируется новый токен (из распределения, заданного логитами), и процесс продолжается, пока не будет сгенерирован токен `EOS` или не будет достигнуто ограничение на длину последовательности. **Обратите внимание**, что вам не нужно прогонять всю последовательность заново через RNN после каждого нового токена, это приведет к квадратичной сложности по длине последовательности. Вам достаточно обновлять скрытое состояние, подавая на вход новый сгенерированный токен и предыдущее скрытое состояние. Кроме того, чтобы получить больше контроля над генерацией, вводится параметр температуры `temp`. Перед семплированием нужно разделить на него логиты, полученные моделью."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "378c1231",
      "metadata": {
        "id": "378c1231"
      },
      "outputs": [],
      "source": [
        "from model import LanguageModel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "ilXnZw5gAPjl",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ilXnZw5gAPjl",
        "outputId": "315a06a6-87e7-4d41-bf9b-dc699b4585a6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "device(type='cpu')"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "99427388",
      "metadata": {
        "id": "99427388"
      },
      "outputs": [],
      "source": [
        "model = LanguageModel(train_set)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "199406f1",
      "metadata": {
        "id": "199406f1"
      },
      "outputs": [],
      "source": [
        "# Код должен проходить тесты\n",
        "for bs in [1, 4, 16, 64, 256]:\n",
        "    indices = torch.randint(high=train_set.vocab_size, size=(bs, train_set.max_length))\n",
        "    lengths = torch.randint(low=1, high=train_set.max_length + 1, size=(bs, ))\n",
        "    logits = model(indices, lengths)\n",
        "    assert logits.shape == (bs, lengths.max(), train_set.vocab_size)\n",
        "\n",
        "for prefix in ['', 'купил мужик шляпу,', 'сел медведь в машину и', 'подумал штирлиц']:\n",
        "    generated = model.inference(prefix, temp=np.random.uniform(0.1, 10))\n",
        "    assert type(generated) == str\n",
        "    assert generated.startswith(prefix)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a7eacf83",
      "metadata": {
        "id": "a7eacf83"
      },
      "source": [
        "## Задание 3: Training (2 балла)\n",
        "\n",
        "Всё, что нам осталось &mdash; реализовать цикл обучения. Заполните пропуски в файле `train.py`. Не забудьте, что мы учим модель предсказывать вероятность следующего, а не текущего токена. Также рекомендуется обрезать батч индексов по самой длинной последовательности, чтобы не гонять паддинги вхолостую. Для оценки качества генерации будем использовать метрику [perplexity](https://towardsdatascience.com/perplexity-in-language-models-87a196019a94). Реализуйте ее подсчет в функции `plot_losses` (да, для этого достаточно только значения лосса).\n",
        "\n",
        "Обучите модель, используя ванильную RNN в качестве рекуррентного слоя. Сохраните чекпойнт обученной модели, он нам еще пригодится."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fd6ab7dd",
      "metadata": {
        "id": "fd6ab7dd"
      },
      "outputs": [],
      "source": [
        "from train import train\n",
        "from torch.utils.data import DataLoader\n",
        "model = LanguageModel(train_set)\n",
        "train_loader = DataLoader(train_set, batch_size=32, shuffle=True)\n",
        "val_loader = DataLoader(valid_set, batch_size=32, shuffle=False)\n",
        "\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3, momentum = 0.9)\n",
        "train(model=model, optimizer=optimizer, scheduler=None, train_loader=train_loader, val_loader=val_loader, num_epochs=5, num_examples=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "pm8DNjQwXo35",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pm8DNjQwXo35",
        "outputId": "a4a33693-7112-4c1f-b8bb-54863138a62a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "device(type='cuda', index=0)"
            ]
          },
          "execution_count": 87,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.save(model.state_dict(), 'first.pth')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "86dad5e1",
      "metadata": {
        "id": "86dad5e1"
      },
      "source": [
        "## Задание 4: LSTM (0.5 балла)\n",
        "\n",
        "Обучите аналогичную модель, но с LSTM в качестве рекуррентного слоя. Сравните модели по метрикам и генерации. Не забывайте про чекпойнты!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d457cd6f",
      "metadata": {
        "id": "d457cd6f"
      },
      "outputs": [],
      "source": [
        "model = LanguageModel(train_set, rnn_type = torch.nn.LSTM)\n",
        "train_loader = DataLoader(train_set, batch_size=32, shuffle=True)\n",
        "val_loader = DataLoader(valid_set, batch_size=32, shuffle=False)\n",
        "\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3, momentum = 0.9)\n",
        "train(model=model, optimizer=optimizer, scheduler=None, train_loader=train_loader, val_loader=val_loader, num_epochs=5, num_examples=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "lLzowWqfsZ4-",
      "metadata": {
        "id": "lLzowWqfsZ4-"
      },
      "outputs": [],
      "source": [
        "torch.save(model.state_dict(), 'second.pth')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2d23819c",
      "metadata": {
        "id": "2d23819c"
      },
      "source": [
        "## Задание 5: Sampling temperature (0.5 балла)\n",
        "\n",
        "Поэкспериментируйте, как результат генерации зависит от параметра температуры. Попробуйте генерацию с разными префиксами. Сделайте выводы."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "14bd1bfb",
      "metadata": {
        "id": "14bd1bfb"
      },
      "outputs": [],
      "source": [
        "# YOUR CODE HERE (⊃｡•́‿•̀｡)⊃━✿✿✿✿✿✿"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ff3967c7",
      "metadata": {
        "id": "ff3967c7"
      },
      "source": [
        "## Задание 5: Tokenizers (1 балл)\n",
        "\n",
        "До сих пор мы использовали BPE токенизатор с относительно небольшим числом токенов (2000 по умолчанию). Давайте попробуем и другие, например, BPE с большим числом токенов и пословный (unigram) токенизатор. Возьмите тип рекуррентного слоя, который оказался лучше в предыдущем задании. Обучите модели на таких токенизаторах и сравните их генерацию. Не забывайте сохранять чекпойнты. Правильно ли сравнивать между собой получившиеся модели по значению perplexity? Почему?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4589b3d9",
      "metadata": {
        "id": "4589b3d9"
      },
      "outputs": [],
      "source": [
        "# YOUR CODE HERE (⊃｡•́‿•̀｡)⊃━✿✿✿✿✿✿"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bc550928",
      "metadata": {
        "id": "bc550928"
      },
      "source": [
        "## Задание 6. Latent Semantic Analysis (2 балла)\n",
        "\n",
        "Попробуем другой подход к оцениванию качества генерации, основанный на [Latent Semantic Analysis](https://en.wikipedia.org/wiki/Latent_semantic_analysis). Реализуйте следующую метрику и сравните по ней модели, обученные с разными токенизаторами:\n",
        "\n",
        "1. Генерируем обученной моделью выборку текстов, совпадающую по размеру с валидационной выборкой.\n",
        "2. Объединяем две выборки текстов (валидационную и сгенерированную) в один корпус. Обратите внимание, что наша токенизация в общем случае необратима, поэтому для чистоты эксперимента нужно закодировать и декодировать валидационную выборку.\n",
        "3. Генерируем tf-idf матрицу для полученного корпуса.\n",
        "4. Понижаем размерность матрицы с помощью [SVD](https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.TruncatedSVD.html).\n",
        "5. Теперь у нас есть векторы, описывающие валидационные и сгенерированные тексты, лежащие в одном пространстве. Для каждого вектора, отвечающего сгенерированному тексту, найдем наибольший cosine similarity между ним и вектором валидационного текста. Усредним такие similarity по всем сгенерированным текстам и получим число, характеризующее похожесть сгенерированной выборки на валидационную.\n",
        "\n",
        "Какие плюсы и минусы есть у описанной метрики?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1415e3c9",
      "metadata": {
        "id": "1415e3c9"
      },
      "outputs": [],
      "source": [
        "# YOUR CODE HERE (⊃｡•́‿•̀｡)⊃━✿✿✿✿✿✿"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "07e632af",
      "metadata": {
        "id": "07e632af"
      },
      "source": [
        "## Задание 7. Visualization (1 балл)\n",
        "\n",
        "В прошлом пункте мы получили векторы, описывающие валидационные и сгенерированные тексты. Попробуем визуализировать их. Примените [TSNE](https://scikit-learn.org/stable/modules/generated/sklearn.manifold.TSNE.html) к этим векторам и нарисуйте scatter-plot с получившимися двумерными представлениями. Точки, соответствующие валидационным и сгенерированным текстам, должны быть разного цвета. Визуализируйте таким образом все три модели для разных токенизаторов."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2aada1d3",
      "metadata": {
        "id": "2aada1d3"
      },
      "outputs": [],
      "source": [
        "# YOUR CODE HERE (⊃｡•́‿•̀｡)⊃━✿✿✿✿✿✿"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "41d9cba5",
      "metadata": {
        "id": "41d9cba5"
      },
      "source": [
        "## Задание 8. ruGPT perplexity (3.5 балла)\n",
        "\n",
        "Подход Latent Semantic Analysis, как и многие другие классические методы, заметно уступает нейросетевым алгоритмам анализа текстов. Вернемся к оцениванию качества генерации с помощью perplexity, для этого возьмем большую и хорошо обученную языковую модель, которая училась на огромном корпусе русских текстов. Считается, что большие языковые модели хорошо выучивают естественный язык, потому с их помощью мы сможем оценивать качество наших маленьких моделей для генерации анекдотов. Для этого мы воспользуемся сервисом [HuggingFace](https://huggingface.co/), который содержит огромное число обученных моделей для самых разных задач. Изучите и реализуйте, [подсчет perplexity](https://huggingface.co/docs/transformers/perplexity), с использованием обученной языковой модели. В качестве модели возьмите [ruGPT3-small](https://huggingface.co/sberbank-ai/rugpt3small_based_on_gpt2). Сгенерируйте синтетические выборки тремя моделями, обученными выше (можете взять выборки из задания 6), и сравните их по perplexity."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cced66c2",
      "metadata": {
        "id": "cced66c2"
      },
      "outputs": [],
      "source": [
        "# YOUR CODE HERE (⊃｡•́‿•̀｡)⊃━✿✿✿✿✿✿"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b3c5d3dc",
      "metadata": {
        "id": "b3c5d3dc"
      },
      "source": [
        "## Бонус (0.1 балл)\n",
        "\n",
        "Покажите лучший анекдот, который удалось сгенерировать вашей модели. Если проверяющий найдет его смешным, то поставит 0.1 балла."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.11.1 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.1"
    },
    "vscode": {
      "interpreter": {
        "hash": "5c7b89af1651d0b8571dde13640ecdccf7d5a6204171d6ab33e7c296e100e08a"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
